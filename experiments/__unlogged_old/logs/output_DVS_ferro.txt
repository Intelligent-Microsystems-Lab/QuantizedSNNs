Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Weight Init (0)
Training: go
Traceback (most recent call last):
  File "test_bench.py", line 180, in <module>
    loss_hist, train_acc, test_acc, result_w = train_classifier_dropconnect(x_data = x_train, y_data = y_train, x_test = x_test, y_test = y_test, nb_epochs = parameters['nb_epochs'], weights = weights, args_snn = parameters, layers = layers, figures = True, verbose=False, p_drop = parameters['p_drop'],  fig_title=ds_name + " "+ parameters['read_out']+" "+ parameters['neuron_type'].__name__ + ' std: '+str(i*1e-5))
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedSNN/snn_training.py", line 105, in train_classifier_dropconnect
    m = run_snn_dropconnect(x_local.to_dense(), y_local, weights, layers, args_snn, p_drop, False)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedSNN/snn_training.py", line 61, in run_snn_dropconnect
    _, spk_temp = args['neuron_type'](inputs=inputs, weights=weights[i-1], args = args, layer=i-1, layer_type = width, infer=infer)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedSNN/neurons.py", line 221, in ferro_neuron
    out = spike_fn(v - (v_thresh_e+theta))
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedSNN/superspike.py", line 36, in forward
    out[input > 0] = 1.0
RuntimeError: CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 11.75 GiB total capacity; 10.67 GiB already allocated; 17.75 MiB free; 10.16 MiB cached)
Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
sys:1: RuntimeWarning: Traceback of forward call that caused the error:
  File "test_bench.py", line 180, in <module>
    loss_hist, train_acc, test_acc, result_w = train_classifier_dropconnect(x_data = x_train, y_data = y_train, x_test = x_test, y_test = y_test, nb_epochs = parameters['nb_epochs'], weights = weights, args_snn = parameters, layers = layers, figures = True, verbose=False, p_drop = parameters['p_drop'],  fig_title=ds_name + " "+ parameters['read_out']+" "+ parameters['neuron_type'].__name__ + ' std: '+str(i*1e-5))
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedSNN/snn_training.py", line 106, in train_classifier_dropconnect
    log_p_y = log_softmax_fn(m)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 493, in __call__
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/activation.py", line 1179, in forward
    return F.log_softmax(input, self.dim, _stacklevel=5)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/functional.py", line 1350, in log_softmax
    ret = input.log_softmax(dim)

Weight Init (0)
Training: go
Traceback (most recent call last):
  File "test_bench.py", line 180, in <module>
    loss_hist, train_acc, test_acc, result_w = train_classifier_dropconnect(x_data = x_train, y_data = y_train, x_test = x_test, y_test = y_test, nb_epochs = parameters['nb_epochs'], weights = weights, args_snn = parameters, layers = layers, figures = True, verbose=False, p_drop = parameters['p_drop'],  fig_title=ds_name + " "+ parameters['read_out']+" "+ parameters['neuron_type'].__name__ + ' std: '+str(i*1e-5))
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedSNN/snn_training.py", line 109, in train_classifier_dropconnect
    loss_val.backward()
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/tensor.py", line 107, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/autograd/__init__.py", line 93, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: Function 'LogSoftmaxBackward' returned nan values in its 0th output.
