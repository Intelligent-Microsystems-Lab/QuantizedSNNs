Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
init done
{'quantization.global_wb': 34, 'inp_mult': 80, 'nb_hidden': 2500, 'nb_steps': 100, 'batch_size': 64, 'quantization.global_lr': 1e-05, 'reg_size': 0.00048219502065459076, 'mult_eq': 0.12, 'class_method': 'integrate'}
Traceback (most recent call last):
  File "spytorch_dvs2_LIF.py", line 476, in <module>
    loss_hist, test_acc, train_acc, best = train(x_train, y_train, lr = quantization.global_lr, nb_epochs = 35)
  File "spytorch_dvs2_LIF.py", line 425, in train
    loss_val.backward()
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/tensor.py", line 118, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/autograd/__init__.py", line 93, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 158.00 MiB (GPU 0; 10.73 GiB total capacity; 2.52 GiB already allocated; 26.56 MiB free; 476.14 MiB cached)
Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
init done
{'quantization.global_wb': 34, 'inp_mult': 80, 'nb_hidden': 2500, 'nb_steps': 100, 'batch_size': 64, 'quantization.global_lr': 1e-05, 'reg_size': 0.00048219502065459076, 'mult_eq': 0.12, 'class_method': 'integrate'}
Epoch 1: loss=3793.72626
Test accuracy: 0.258
Train accuracy: 0.230
Epoch 2: loss=1205.89267
Test accuracy: 0.285
Train accuracy: 0.458
Epoch 3: loss=559.89647
Test accuracy: 0.309
Train accuracy: 0.666
Epoch 4: loss=272.11597
Test accuracy: 0.316
Train accuracy: 0.782
Epoch 5: loss=118.40199
Test accuracy: 0.277
Train accuracy: 0.869
Epoch 6: loss=66.15027
Test accuracy: 0.312
Train accuracy: 0.919
Epoch 7: loss=33.35351
Test accuracy: 0.332
Train accuracy: 0.944
Epoch 8: loss=21.39625
Test accuracy: 0.316
Train accuracy: 0.957
Epoch 9: loss=12.82326
Test accuracy: 0.305
Train accuracy: 0.964
Epoch 10: loss=7.65190
Test accuracy: 0.316
Train accuracy: 0.984
Epoch 11: loss=4.85532
Test accuracy: 0.316
Train accuracy: 0.994
Epoch 12: loss=4.55134
Test accuracy: 0.324
Train accuracy: 0.997
Epoch 13: loss=4.21512
Test accuracy: 0.312
Train accuracy: 0.997
Epoch 14: loss=4.03598
Test accuracy: 0.320
Train accuracy: 0.998
Epoch 15: loss=3.83125
Test accuracy: 0.305
Train accuracy: 0.998
Epoch 16: loss=3.72743
Test accuracy: 0.301
Train accuracy: 0.998
Epoch 17: loss=3.58229
Test accuracy: 0.336
Train accuracy: 0.998
Epoch 18: loss=3.51589
Test accuracy: 0.340
Train accuracy: 0.998
Epoch 19: loss=3.40838
Test accuracy: 0.324
Train accuracy: 0.998
Epoch 20: loss=3.38042
Test accuracy: 0.336
Train accuracy: 0.998
Epoch 21: loss=3.35572
Test accuracy: 0.309
Train accuracy: 0.998
Epoch 22: loss=3.33906
Test accuracy: 0.324
Train accuracy: 0.998
Epoch 23: loss=3.32094
Test accuracy: 0.332
Train accuracy: 0.998
Epoch 24: loss=3.31511
Test accuracy: 0.301
Train accuracy: 0.998
Epoch 25: loss=3.28911
Test accuracy: 0.305
Train accuracy: 0.998
Epoch 26: loss=3.24353
Test accuracy: 0.320
Train accuracy: 0.998
Epoch 27: loss=3.22637
Test accuracy: 0.328
Train accuracy: 0.998
Epoch 28: loss=3.20992
Test accuracy: 0.320
Train accuracy: 0.998
Epoch 29: loss=3.20957
Test accuracy: 0.328
Train accuracy: 0.998
Epoch 30: loss=3.20921
Test accuracy: 0.320
Train accuracy: 0.998
Epoch 31: loss=3.19809
Test accuracy: 0.324
Train accuracy: 0.998
Epoch 32: loss=3.19561
Test accuracy: 0.320
Train accuracy: 0.998
Epoch 33: loss=3.19520
Test accuracy: 0.328
Train accuracy: 0.998
Epoch 34: loss=3.19481
Test accuracy: 0.309
Train accuracy: 0.998
Epoch 35: loss=3.18987
Test accuracy: 0.301
Train accuracy: 0.998
{'quantization.global_wb': 34, 'inp_mult': 80, 'reg_size': 0.00048219502065459076, 'weight_sum': 1.12}
Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
init done
{'quantization.global_wb': 34, 'inp_mult': 80, 'nb_hidden': 2500, 'nb_steps': 100, 'batch_size': 64, 'quantization.global_lr': 1e-05, 'reg_size': 0.00048219502065459076, 'mult_eq': 0.12, 'class_method': 'integrate'}
Epoch 1: loss=2841.35887
Test accuracy: 0.293
Train accuracy: 0.248
Epoch 2: loss=823.28380
Test accuracy: 0.324
Train accuracy: 0.555
Epoch 3: loss=360.44346
Test accuracy: 0.363
Train accuracy: 0.704
Epoch 4: loss=167.79855
Test accuracy: 0.336
Train accuracy: 0.820
Epoch 5: loss=74.29002
Test accuracy: 0.383
Train accuracy: 0.887
Epoch 6: loss=35.82076
Test accuracy: 0.336
Train accuracy: 0.936
Epoch 7: loss=16.91011
Test accuracy: 0.316
Train accuracy: 0.964
Epoch 8: loss=9.42035
Test accuracy: 0.336
Train accuracy: 0.976
Epoch 9: loss=4.86804
Test accuracy: 0.344
Train accuracy: 0.985
Epoch 10: loss=3.53664
Test accuracy: 0.340
Train accuracy: 0.985
Epoch 11: loss=1.65720
Test accuracy: 0.340
Train accuracy: 0.997
Epoch 12: loss=1.36116
Test accuracy: 0.328
Train accuracy: 0.998
Epoch 13: loss=1.34403
Test accuracy: 0.355
Train accuracy: 1.000
Epoch 14: loss=1.34402
Test accuracy: 0.332
Train accuracy: 1.000
Epoch 15: loss=1.34400
Test accuracy: 0.328
Train accuracy: 1.000
Epoch 16: loss=1.34399
Test accuracy: 0.355
Train accuracy: 1.000
Epoch 17: loss=1.34398
Test accuracy: 0.336
Train accuracy: 1.000
Epoch 18: loss=1.34397
Test accuracy: 0.332
Train accuracy: 1.000
Epoch 19: loss=1.34396
Test accuracy: 0.332
Train accuracy: 1.000
Epoch 20: loss=1.34396
Test accuracy: 0.352
Train accuracy: 1.000
Epoch 21: loss=1.34396
Test accuracy: 0.324
Train accuracy: 1.000
Epoch 22: loss=1.34396
Test accuracy: 0.320
Train accuracy: 1.000
Epoch 23: loss=1.34396
Test accuracy: 0.316
Train accuracy: 1.000
Epoch 24: loss=1.34395
Test accuracy: 0.348
Train accuracy: 1.000
Epoch 25: loss=1.34395
Test accuracy: 0.352
Train accuracy: 1.000
Epoch 26: loss=1.34395
Test accuracy: 0.312
Train accuracy: 1.000
Epoch 27: loss=1.34395
Test accuracy: 0.320
Train accuracy: 1.000
Epoch 28: loss=1.34395
Test accuracy: 0.328
Train accuracy: 1.000
Epoch 29: loss=1.34395
Test accuracy: 0.320
Train accuracy: 1.000
Epoch 30: loss=1.34395
Test accuracy: 0.320
Train accuracy: 1.000
Epoch 31: loss=1.34395
Test accuracy: 0.320
Train accuracy: 1.000
Epoch 32: loss=1.34395
Test accuracy: 0.340
Train accuracy: 1.000
Epoch 33: loss=1.34395
Test accuracy: 0.328
Train accuracy: 1.000
Epoch 34: loss=1.34395
Test accuracy: 0.324
Train accuracy: 1.000
Epoch 35: loss=1.34395
Test accuracy: 0.332
Train accuracy: 1.000
{'quantization.global_wb': 34, 'inp_mult': 80, 'reg_size': 0.00048219502065459076, 'weight_sum': 1.12}
Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
init done
{'quantization.global_wb': 34, 'inp_mult': 80, 'nb_hidden': 2500, 'nb_steps': 100, 'batch_size': 64, 'quantization.global_lr': 1e-05, 'reg_size': 0.00048219502065459076, 'mult_eq': 0.12, 'class_method': 'integrate'}
Epoch 1: loss=4420.56672
Test accuracy: 0.309
Train accuracy: 0.201
Epoch 2: loss=1049.91152
Test accuracy: 0.316
Train accuracy: 0.475
Epoch 3: loss=431.82262
Test accuracy: 0.332
Train accuracy: 0.691
Epoch 4: loss=210.78576
Test accuracy: 0.371
Train accuracy: 0.807
Epoch 5: loss=99.52110
Test accuracy: 0.371
Train accuracy: 0.878
Epoch 6: loss=56.42923
Test accuracy: 0.363
Train accuracy: 0.921
Epoch 7: loss=28.26940
Test accuracy: 0.391
Train accuracy: 0.952
Epoch 8: loss=15.88382
Test accuracy: 0.391
Train accuracy: 0.965
Epoch 9: loss=9.72632
Test accuracy: 0.395
Train accuracy: 0.977
Epoch 10: loss=6.22062
Test accuracy: 0.359
Train accuracy: 0.983
Epoch 11: loss=4.10160
Test accuracy: 0.383
Train accuracy: 0.998
Epoch 12: loss=3.86257
Test accuracy: 0.367
Train accuracy: 0.998
Epoch 13: loss=2.63645
Test accuracy: 0.375
Train accuracy: 0.999
Epoch 14: loss=3.61196
Test accuracy: 0.375
Train accuracy: 0.998
Epoch 15: loss=3.48625
Test accuracy: 0.375
Train accuracy: 0.998
Epoch 16: loss=3.37357
Test accuracy: 0.371
Train accuracy: 0.998
Epoch 17: loss=3.32660
Test accuracy: 0.379
Train accuracy: 0.998
Epoch 18: loss=3.15445
Test accuracy: 0.363
Train accuracy: 0.998
Epoch 19: loss=3.06217
Test accuracy: 0.379
Train accuracy: 0.998
Epoch 20: loss=3.04824
Test accuracy: 0.352
Train accuracy: 0.998
Epoch 21: loss=3.02213
Test accuracy: 0.363
Train accuracy: 0.998
Epoch 22: loss=2.98990
Test accuracy: 0.359
Train accuracy: 0.998
Epoch 23: loss=2.95917
Test accuracy: 0.371
Train accuracy: 0.998
Epoch 24: loss=2.94695
Test accuracy: 0.363
Train accuracy: 0.998
Epoch 25: loss=2.92347
Test accuracy: 0.387
Train accuracy: 0.998
Epoch 26: loss=2.86004
Test accuracy: 0.379
Train accuracy: 0.998
Epoch 27: loss=2.85567
Test accuracy: 0.379
Train accuracy: 0.998
Epoch 28: loss=2.84166
Test accuracy: 0.371
Train accuracy: 0.998
Epoch 29: loss=2.86040
Test accuracy: 0.387
Train accuracy: 0.998
Epoch 30: loss=2.84125
Test accuracy: 0.379
Train accuracy: 0.998
Epoch 31: loss=2.84092
Test accuracy: 0.387
Train accuracy: 0.998
Epoch 32: loss=2.84045
Test accuracy: 0.383
Train accuracy: 0.998
Epoch 33: loss=2.83574
Test accuracy: 0.375
Train accuracy: 0.998
Epoch 34: loss=2.83543
Test accuracy: 0.363
Train accuracy: 0.998
Epoch 35: loss=2.84585
Test accuracy: 0.379
Train accuracy: 0.998
{'quantization.global_wb': 34, 'inp_mult': 80, 'reg_size': 0.00048219502065459076, 'weight_sum': 1.12}
